\documentclass[letterpaper,12pt]{article}

\usepackage{fontawesome}
\usepackage{latexsym}
\usepackage[empty]{fullpage}
\usepackage{titlesec}
\usepackage{marvosym}
\usepackage[usenames,dvipsnames]{color}
\usepackage{verbatim}
\usepackage{enumitem}
\usepackage[hidelinks]{hyperref}
\usepackage{fancyhdr}
\usepackage[english]{babel}
\usepackage{tabularx}
\usepackage{hyperref}

\pagestyle{fancy}
\fancyhf{} % clear all header and footer fields
\fancyfoot{}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}

% Adjust margins
% \addtolength{\oddsidemargin}{-0.5in}
% \addtolength{\evensidemargin}{-0.5in}
% \addtolength{\textwidth}{1in}
% \addtolength{\topmargin}{-.3in}
% \addtolength{\textheight}{1.0in}
% \usepackage[left=0.5in,top=0.6in,right=0.5in,bottom=0.6in]{geometry}
\usepackage[left=0.5in,top=1in,right=0.5in,bottom=1in]{geometry}
% \usepackage[margin=0.8in]{geometry}

\urlstyle{same}

\raggedbottom
\raggedright
\setlength{\tabcolsep}{0in}

% Sections formatting
\titleformat{\section}{
  \vspace{-4pt}\scshape\raggedright\large
}{}{0em}{}[\color{black}\titlerule \vspace{-5pt}]

%-------------------------
% Custom commands
\newcommand{\resumeItem}[2]{
\item\small{
    \textbf{#1}{: #2 \vspace{-2pt}}
  }
}

\newcommand{\resumeSubheading}[4]{
  \vspace{-1pt}
\item
  \begin{tabular*}{0.97\textwidth}[t]{l@{\extracolsep{\fill}}r}
    \textbf{#1} & #2 \\
    \textit{\small#3} & \textit{\small #4} \\
  \end{tabular*}\vspace{-5pt}
}

\newcommand{\resumeSubheadingTitleOnly}[1]{
  \vspace{-1pt}
\item
  \textbf{#1}
  \vspace{-5pt}
}

\newcommand{\resumeSubSubheading}[2]{
  \begin{tabular*}{0.97\textwidth}{l@{\extracolsep{\fill}}r}
    \textit{\small#1} & \textit{\small #2} \\
  \end{tabular*}\vspace{-5pt}
}

\newcommand{\resumeSubItem}[2]{\resumeItem{#1}{#2}\vspace{-4pt}}

\renewcommand{\labelitemii}{$\circ$}

\newcommand{\resumeSubHeadingListStart}{
\begin{itemize}[leftmargin=*, label={}]}
    \newcommand{\resumeSubHeadingListEnd}{
  \end{itemize}}
\newcommand{\resumeItemListStart}{
\begin{itemize}}
    \newcommand{\resumeItemListEnd}{
  \end{itemize}\vspace{-5pt}}

%-------------------------------------------
%%%%%%  CV STARTS HERE  %%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

%----------HEADING-----------------
% \begin{tabular*}{\textwidth}{l@{\extracolsep{\fill}}r}
%   \textbf{\Large Changyu Gao} & Email : \href{mailto:changyu.gao@wisc.edu}{changyu.gao@wisc.edu}\\
%   \href{http://sourabhbajaj.com/}{http://www.sourabhbajaj.com} & Mobile : +1 (608) 949-4659\\
% \end{tabular*}

\begin{center}
  \textbf{\Huge Changyu Gao}
  \begin{center}
    \begin{tabular}{c}
      \href{mailto:changyu.gao@wisc.edu}{Email:changyu.gao@wisc.edu} \\
      \faGithub \, \href{https://github.com/cyugao}{cyugao} \, \faLinkedin \, \href{https://www.linkedin.com/in/changyu-gao}{in/changyu-gao}
    \end{tabular}
  \end{center}
\end{center}

%-----------EDUCATION-----------------
\section{Education}
\resumeSubHeadingListStart
\resumeSubheading
{University of Wisconsin--Madison}{Madison, WI}
{Ph.D. Candidate in Industrial Engineering, Optimization Track}{Sep 2019 -- June 2025 (Expected)}
% \textit{\small{M.S. Student in Computer Science}}\textit{\small{Feb 2021 -- Present}}
\resumeSubheading
{University of Wisconsin--Madison}{Madison, WI}
{M.S., Computer Science}{Feb 2021 -- June 2024}
\resumeSubheading
{University of Science and Technology of China}{Hefei, China}
{B.S., Mathematics and Applied Mathematics \emph{(Outstanding Graduate)}}{Aug 2015 -- June 2019}
\resumeSubHeadingListEnd

\section{Research Experience}
\textit{Advisor:} \textup{\textbf{Prof. Stephen Wright}} (All projects below are in collaboration with Prof. Wright)

Summary: design and analysis of optimization algorithms for machine learning applications.

\resumeSubHeadingListStart

\resumeSubheadingTitleOnly{Optimal Rates for Robust Stochastic Convex Optimization \\
{\normalfont \textit{Collaborator:}} Andrew Lowy, Xingyu Zhou}
\begin{itemize}
  \item Developed novel stochastic convex optimization algorithms with robustness guarantees.
  \item Achieved first optimal-rate results for robust stochastic convex optimization.
  \item Significantly improved sample complexity and relaxed strict requirements of existing algorithms, broadening their applicability.
\end{itemize}

\resumeSubheadingTitleOnly{Private Federated Learning \\
{\normalfont \textit{Collaborator:}} Andrew Lowy, Xingyu Zhou}
\begin{itemize}
  \item Designed novel federated learning algorithm with privacy guarantees for heterogeneous data
  \item Achieved optimal population excess risk bounds, surpassing previous state-of-the-art methods.
  \item Significantly improved the communication and gradient complexity over SOTA algorithms.
\end{itemize}

\resumeSubheadingTitleOnly{Differentially Private Optimization}
\begin{itemize}
  \item Innovated differentially private algorithms for finding approximate second-order stationary points
  \item Implemented adaptive line search and mini-batching strategies to enhance practical performance.
  \item Developed PyTorch implementation demonstrating empirical effectiveness through experiments.
\end{itemize}

% \resumeSubheadingTitleOnly{Neural Collapse and Loss Function Design \\ {\normalfont \textit{Collaborator:}} Yiqiao Zhong}
%   \begin{itemize}
%     \item Conducted extensive experiments to examine the impact of diverse loss functions on the neural collapse phenomenon.
%     % \item Investigated the convergence behavior of different loss functions.
%     \item Characterized and analyzed the convergence behavior for the cross entropy loss function with label smoothing, for linearly separable data.
%   \end{itemize}

\resumeSubheadingTitleOnly{Optimization Methods for Probabilistic Soft Logic (PSL) \\
{\normalfont \textit{Collaborator:}} Charles Dickens, Connor Pryor, Lise Getoor}
\begin{itemize}
  \item Implemented and tested HOGWILD! and Frank-Wolfe methods for PSL framework using Java.
  \item Executed inference experiments on real-world datasets, validating the practicality of these methods.
  \item Proved theoretical guarantees for the proposed bilevel formulation of PSL
\end{itemize}

\resumeSubheadingTitleOnly{Parameter Learning with Derivative-Free Optimization (DFO) Methods}
\begin{itemize}
  \item Implemented the parameter learning procedure for Lorenz96 model using DFO methods in Python
  \item Performed optimization with inexact function values using interpolation and Bayesian methods
\end{itemize}

% \resumeItem{Subseasonal Climate Forecasting}
% {Improved the parameter estimation with ensembles. Investigated the sensitivity of the dynamic systems. Implemented model reduction methods in Python.}
\resumeSubHeadingListEnd

%-----------EXPERIENCE-----------------
\section{Work Experience}
\resumeSubHeadingListStart

% --------Multiple Positions Heading------------
%    \resumeSubSubheading
%     {Software Engineer I}{Oct 2014 - Sep 2016}
%     \resumeItemListStart
%        \resumeItem{Apache Beam}
%          {Apache Beam is a unified model for defining both batch and streaming data-parallel processing pipelines}
%     \resumeItemListEnd
%    \resumeSubHeadingListEnd
%-------------------------------------------

\resumeSubheading {Research Scientist Intern, Meta}{Menlo Park, CA}
{Team: \textup{\textbf{Meta AI Research (FAIR) -- Reality Labs}}}{Sep 2022 -- Jan 2023}
\resumeItemListStart
\resumeItem{Adaptive Training for Transformer-based Models}{
  \begin{itemize}
    \item Developed adaptive training algorithms and engineered gradient statistics analysis framework
    \item Achieved baseline performance with reduced computation, improving training efficiency for transformer-based models
    \item Contributed to Meta's FairScale library, resolving critical gradient accumulation issues
  \end{itemize}
}
\resumeItemListEnd

\resumeSubheading {Applied Scientist Intern, Amazon}{Seattle, WA}
{Team: \textup{\textbf{Delivery Experience (DEX) -- AI}}}{May 2021 -- Aug 2021}
\resumeItemListStart
\resumeItem{Mining Inconsistency Issues using Semantic Search Model}{
  \begin{itemize}
    \item Developed semantic search system for detecting customer experience inconsistencies using \textit{natural language processing} techniques
    \item Enhanced search accuracy through \textit{fine-tuning} approaches in TensorFlow
    \item Identified and escalated critical inconsistency issues to the corresponding teams
  \end{itemize}
}
\resumeItemListEnd

% \resumeSubheading
% {Research Assistant, University of Science and Technology of China}{Hefei, China}
% {Advisor: \textup{\textbf{Liansheng Zhuang}}}{Mar 2019 -- May 2019}
% \resumeItemListStart
% \resumeItem{Complex-valued Neural Network}
% {Surveyed various types of complex-valued neural networks. Implemented Associative LSTM in Keras. Validated its performance with experiments.}
% \resumeItemListEnd

\resumeSubHeadingListEnd

%-----------PROJECTS-----------------
% \section{Selected Projects}
% \resumeSubHeadingListStart
% \resumeSubItem{Distribution System Optimization}
% {Modeling of two-stage optimization of the distribution system. Implemented in GAMS and Python. Data is collected and cleaned using BeautifulSoup and Pandas.}
% \resumeSubItem{Knapsack Problem}
% {Implemented various algorithms to solve the problem: depth first search, best first search and dynamic programming. Implemented branch and bound method to prune the search space.}
% % \resumeSubItem{Stock Info Visualization with Dash}
% % {Interactive visualization of stock historical information using Dash Framework. Wrote the data storage and update logic with callback functions.}
% \resumeSubHeadingListEnd

%
% --------PROGRAMMING SKILLS------------
\section{Programming Skills}
\resumeSubHeadingListStart

\resumeSubItem{Languages}{Proficient: Python. Familiar: SQL, R, C, C++, Java}

\resumeSubItem{Frameworks}{Pytorch, Tensorflow, JAX, Pandas, Numpy, Scipy}

\resumeSubHeadingListEnd

% --------PUBLICATIONS------------
\section{Publications}

\begin{itemize}[leftmargin=*, label={}]
  \item \textbf{Changyu Gao}, Andrew Lowy, Stephen J. Wright, Xingyu Zhou. Optimal Rates for Robust Stochastic Convex Optimization, to appear in the 6th annual Symposium on Foundations of Responsible Computing (\textbf{FORC 2025}).

  \item
    \textbf{Changyu Gao}, Andrew Lowy, Stephen J. Wright, Xingyu Zhou. Private Heterogeneous Federated Learning Without a Trusted Server Revisited: Error-Optimal and Communication-Efficient Algorithms for Convex Losses, Proceedings of the 41st International Conference on Machine Learning (\textbf{ICML 2024}), Vienna, Austria. PMLR 235, 2024. [\textbf{Poster Award}, Midwest Machine Learning Symposium 2024]

  \item \textbf{Changyu Gao} and Stephen J. Wright. Differentially Private Optimization for Smooth Nonconvex ERM,
    \href{https://arxiv.org/abs/2302.04972}{arXiv preprint} arXiv:2302.04972 (2023). [Theory and Practice of Differential Privacy (TPDP 2023) Poster]

  \item
    Charles Andrew Dickens, \textbf{Changyu Gao}, Connor Pryor, Stephen J. Wright, Lise Getoor.
    Convex and Bilevel Optimization for Neuro-Symbolic Inference and Learning, Proceedings of the 41st International Conference on Machine Learning (\textbf{ICML 2024}), Vienna, Austria. PMLR 235, 2024.
  
  \item Charles Andrew Dickens, Connor Pryor, \textbf{Changyu Gao}, Alon Albalak, Eriq Augustine, William Wang, Stephen J. Wright, and Lise Getoor. A mathematical framework, a taxonomy of modeling paradigms, and a suite of learning techniques for neural-symbolic systems, arXiv preprint arXiv:2407.09693 (2024).
\end{itemize}
% add some space between
\vspace{0.2cm}
\textbf{Hobbies and interests}: music, guitar, hiking, learning foreign languages, reading (especially nonfiction), listening to podcasts, interests in new technology/gadgets and social issues.

\textbf{Languages}: English (fluent), Chinese (native), French (intermediate B2), Spanish (basic).
%-------------------------------------------
\end{document}
