\documentclass[letterpaper,12pt]{article}

\usepackage{fontawesome}
\usepackage{latexsym}
\usepackage[empty]{fullpage}
\usepackage{titlesec}
\usepackage{marvosym}
\usepackage[usenames,dvipsnames]{color}
\usepackage{verbatim}
\usepackage{enumitem}
\usepackage[hidelinks]{hyperref}
\usepackage{fancyhdr}
\usepackage[english]{babel}
\usepackage{tabularx}
\usepackage{hyperref}


\pagestyle{fancy}
\fancyhf{} % clear all header and footer fields
\fancyfoot{}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}

% Adjust margins
% \addtolength{\oddsidemargin}{-0.5in}
% \addtolength{\evensidemargin}{-0.5in}
% \addtolength{\textwidth}{1in}
% \addtolength{\topmargin}{-.3in}
% \addtolength{\textheight}{1.0in}
% \usepackage[left=0.5in,top=0.6in,right=0.5in,bottom=0.6in]{geometry}
\usepackage[left=0.5in,top=1in,right=0.5in,bottom=1in]{geometry}
% \usepackage[margin=0.8in]{geometry}

\urlstyle{same}

\raggedbottom
\raggedright
\setlength{\tabcolsep}{0in}

% Sections formatting
\titleformat{\section}{
  \vspace{-4pt}\scshape\raggedright\large
}{}{0em}{}[\color{black}\titlerule \vspace{-5pt}]

%-------------------------
% Custom commands
\newcommand{\resumeItem}[2]{
  \item\small{
    \textbf{#1}{: #2 \vspace{-2pt}}
  }
}

\newcommand{\resumeSubheading}[4]{
  \vspace{-1pt}\item
    \begin{tabular*}{0.97\textwidth}[t]{l@{\extracolsep{\fill}}r}
      \textbf{#1} & #2 \\
      \textit{\small#3} & \textit{\small #4} \\
    \end{tabular*}\vspace{-5pt}
}

\newcommand{\resumeSubheadingTitleOnly}[1]{
  \vspace{-1pt}\item
    \textbf{#1}
  \vspace{-5pt}
}

\newcommand{\resumeSubSubheading}[2]{
    \begin{tabular*}{0.97\textwidth}{l@{\extracolsep{\fill}}r}
      \textit{\small#1} & \textit{\small #2} \\
    \end{tabular*}\vspace{-5pt}
}

\newcommand{\resumeSubItem}[2]{\resumeItem{#1}{#2}\vspace{-4pt}}

\renewcommand{\labelitemii}{$\circ$}

\newcommand{\resumeSubHeadingListStart}{\begin{itemize}[leftmargin=*, label={}]}
\newcommand{\resumeSubHeadingListEnd}{\end{itemize}}
\newcommand{\resumeItemListStart}{\begin{itemize}}
\newcommand{\resumeItemListEnd}{\end{itemize}\vspace{-5pt}}

%-------------------------------------------
%%%%%%  CV STARTS HERE  %%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{document}

%----------HEADING-----------------
% \begin{tabular*}{\textwidth}{l@{\extracolsep{\fill}}r}
%   \textbf{\Large Changyu Gao} & Email : \href{mailto:changyu.gao@wisc.edu}{changyu.gao@wisc.edu}\\
%   \href{http://sourabhbajaj.com/}{http://www.sourabhbajaj.com} & Mobile : +1 (608) 949-4659\\
% \end{tabular*}

\begin{center}
  \textbf{\Huge Changyu Gao}
\begin{center}
  \begin{tabular}{c}
    \href{mailto:changyu.gao@wisc.edu}{Email:changyu.gao@wisc.edu} \\
    \faGithub \, \href{https://github.com/cyugao}{cyugao} \, \faLinkedin \, \href{https://www.linkedin.com/in/changyu-gao}{in/changyu-gao}
  \end{tabular}
\end{center}
\end{center}

%-----------EDUCATION-----------------
\section{Education}
\resumeSubHeadingListStart
\resumeSubheading
{University of Wisconsin--Madison}{Madison, WI}
{Ph.D. Student in Industrial Engineering, Optimization Track}{Sep 2019 -- Aug 2025 (Expected)}
% \textit{\small{M.S. Student in Computer Science}}\textit{\small{Feb 2021 -- Present}}
\resumeSubheading
{University of Wisconsin--Madison}{Madison, WI}
{M.S., Computer Science}{Feb 2021 -- June 2024}
\resumeSubheading
{University of Science and Technology of China}{Hefei, China}
{B.S., Mathematics and Applied Mathematics \emph{(Outstanding Graduate)}}{Aug 2015 -- June 2019}
\resumeSubHeadingListEnd

\section{Research Experience}
\textit{Advisor:} \textup{\textbf{Prof. Stephen Wright}}

Summary: design algorithms that solves mathematical optimization problems with theoretical guarantees.

\resumeSubHeadingListStart

\resumeSubheadingTitleOnly{Private Federated Learning \\
{\normalfont \textit{Collaborator:}} Dr. Andrew Lowy, Dr. Xingyu Zhou}
  \begin{itemize}
    \item Developed a novel federated learning algorithm with inter-silo record-level DP guarantees, combining the phased localization technique and a private federated learning version of SGD.
    \item Our algorithm achieves the \textit{optimal} population excess risk bound for heterogeneous data distributions; previous algorithms only achieve suboptimal bounds.
    \item Significantly improved the communication and gradient complexity over SOTA algorithms.
  \end{itemize}

\resumeSubheadingTitleOnly{Differentially Private Optimization for Smooth Nonconvex ERM}
  \begin{itemize}
    \item Designed differentially private optimization algorithms for finding an approximate second-order stationary point with convergence guarantees.
    \item Proposed line search, mini-batching, and a two-phase strategy to improve the speed and practicality of the algorithms.
    \item Implemented the algorithm using Pytorch and demonstrated its performance through experiments.
  \end{itemize}

% \resumeSubheadingTitleOnly{Neural Collapse and Loss Function Design \\ {\normalfont \textit{Collaborator:}} Dr. Yiqiao Zhong}
%   \begin{itemize}
%     \item Conducted extensive experiments to examine the impact of diverse loss functions on the neural collapse phenomenon.
%     % \item Investigated the convergence behavior of different loss functions.
%     \item Characterized and analyzed the convergence behavior for the cross entropy loss function with label smoothing, for linearly separable data.
%   \end{itemize}


\resumeSubheadingTitleOnly{Optimization Methods for Probabilistic Soft Logic (PSL)}
  \begin{itemize}
    \item Implemented and tested HOGWILD! and Frank-Wolfe methods for PSL framework using Java.
    \item Executed inference experiments on real-world datasets, validating the practicality of these methods.
    \item Proved theoretical guarantees for the proposed bilevel formulation of PSL.
  \end{itemize}


\resumeSubheadingTitleOnly{Parameter Learning with Derivative-Free Optimization (DFO) Methods}
  \begin{itemize}
    \item Implemented the parameter learning procedure for Lorenz96 model using DFO methods in Python.
    \item Performed optimization with uncertainty function values using soft interpolation and Gaussian Process methods.
  \end{itemize}

% \resumeItem{Subseasonal Climate Forecasting}
% {Improved the parameter estimation with ensembles. Investigated the sensitivity of the dynamic systems. Implemented model reduction methods in Python.}
\resumeSubHeadingListEnd

%-----------EXPERIENCE-----------------
\section{Work Experience}
\resumeSubHeadingListStart

% --------Multiple Positions Heading------------
%    \resumeSubSubheading
%     {Software Engineer I}{Oct 2014 - Sep 2016}
%     \resumeItemListStart
%        \resumeItem{Apache Beam}
%          {Apache Beam is a unified model for defining both batch and streaming data-parallel processing pipelines}
%     \resumeItemListEnd
%    \resumeSubHeadingListEnd
%-------------------------------------------




\resumeSubheading {Research Scientist Intern, Meta}{Menlo Park, CA}
{Team: \textup{\textbf{Meta AI (FAIR) -- Reality Labs}, supervised by \textbf{Dr. Min Xu}}}{Sep 2022 -- Jan 2023}
\resumeItemListStart
\resumeItem{Adaptive Training for Transformer-based Models}{
  \begin{itemize}
    \item Contributed to the open source project \href{https://github.com/facebookresearch/fairscale}{fairscale}.
    Fixed gradient accumulation bugs.
    \item Implemented methods to collect and analyze the gradient statistics during training of the Translation task using the Transformer model.
    Based on the gradient statistics, designed and implemented an adaptive training method to improve the training efficiency.
    \item Our algorithm uses the gradient statistics to dynamically adjust the gradient accumulation steps and the learning rate, achieving the baseline with better efficiency.
  \end{itemize}
}
\resumeItemListEnd

\resumeSubheading {Applied Scientist Intern, Amazon}{Seattle, WA}
{Team: \textup{\textbf{Delivery Experience (DEX) -- AI}}}{May 2021 -- Aug 2021}
\resumeItemListStart
\resumeItem{Mining Inconsistency Issues using Semantic Search Model}{
  \begin{itemize}
    \item Applied the semantic search model to the customer contact data, facilitating inconsistency detection.
    \item Collected and refined the queries for semantic search; oversaw the data annotation process.
    \item Implemented two fine-tuning schemes of the encoder used in the semantic search model in Tensorflow and thus improved the search model accuracy.
    \item Important inconsistency issues discovered were escalated to the corresponding issue owners.
  \end{itemize}
}
\resumeItemListEnd

% \resumeSubheading
% {Research Assistant, University of Science and Technology of China}{Hefei, China}
% {Advisor: \textup{\textbf{Liansheng Zhuang}}}{Mar 2019 -- May 2019}
% \resumeItemListStart
% \resumeItem{Complex-valued Neural Network}
% {Surveyed various types of complex-valued neural networks. Implemented Associative LSTM in Keras. Validated its performance with experiments.}
% \resumeItemListEnd


\resumeSubHeadingListEnd


%-----------PROJECTS-----------------
% \section{Selected Projects}
% \resumeSubHeadingListStart
% \resumeSubItem{Distribution System Optimization}
% {Modeling of two-stage optimization of the distribution system. Implemented in GAMS and Python. Data is collected and cleaned using BeautifulSoup and Pandas.}
% \resumeSubItem{Knapsack Problem}
% {Implemented various algorithms to solve the problem: depth first search, best first search and dynamic programming. Implemented branch and bound method to prune the search space.}
% % \resumeSubItem{Stock Info Visualization with Dash}
% % {Interactive visualization of stock historical information using Dash Framework. Wrote the data storage and update logic with callback functions.}
% \resumeSubHeadingListEnd

%
% --------PROGRAMMING SKILLS------------
\section{Programming Skills}
\resumeSubHeadingListStart

\resumeSubItem{Languages}{Proficient: Python. Familiar: SQL, R, C, C++, Java}

\resumeSubItem{Frameworks}{Pytorch, Tensorflow, JAX, Pandas, Numpy, Scipy}

\resumeSubHeadingListEnd

% --------PUBLICATIONS------------
\section{Publications}

\begin{itemize}[leftmargin=*, label={}]
  \item 	
  \textbf{Changyu Gao}, Andrew Lowy, Stephen Wright, Xingyu Zhou. Private Heterogeneous Federated Learning Without a Trusted Server Revisited: Error-Optimal and Communication-Efficient Algorithms for Convex Losses, \textbf{ICML} 2024.

  \item 
  \textbf{Changyu Gao} and Stephen J Wright. Differentially Private Optimization for Smooth Nonconvex ERM,
  \href{https://arxiv.org/abs/2302.04972}{arXiv preprint}. \href{https://tpdp.journalprivacyconfidentiality.org/2023/}{TPDP 2023} Poster.

  \item
  Charles Andrew Dickens, \textbf{Changyu Gao}, Connor Pryor, Stephen Wright, Lise Getoor.
  Convex and Bilevel Optimization for Neuro-Symbolic Inference and Learning, \textbf{ICML} 2024.

\end{itemize}
% add some space between
\vspace{0.2cm}
\textbf{Hobbies and interests}: music, guitar, hiking, tech, society, language, reading, podcasts.

%-------------------------------------------
\end{document}
